{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SGA CRISPR Cas Systems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from Bio import SearchIO\n",
    "from Bio import SeqIO\n",
    "import json\n",
    "from collections import defaultdict\n",
    "import skbio\n",
    "import subprocess as sp\n",
    "from collections import OrderedDict\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "from Bio.SeqFeature import SeqFeature, FeatureLocation\n",
    "from Bio.Seq import Seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rootdir = \"to_fill_in\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "starting folders in rootdir:\n",
    "1. All_genomes\n",
    "2. All_genomes_proteins\n",
    "3. metadata\n",
    "4. Scripts (with parallel-fastq-dump, process_reads_bbmap, crispr v6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makedir(path):\n",
    "    if not os.path.isdir(path):\n",
    "        os.mkdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating dictionary to match scaffolds to a bin name\n",
    "scaf2bin_dic = {}\n",
    "for file in glob.glob(rootdir + \"All_genomes/*fna\"):\n",
    "    name = file.replace(rootdir + \"All_genomes/\", \"\").replace(\".fna\", \"\")\n",
    "    for record in SeqIO.parse(open(file), \"fasta\"):\n",
    "        scaf2bin_dic[record.description.split(\" \")[0]] = name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating dictionary to match SGA taxonomy with bin name\n",
    "\n",
    "bin2tax_dict = {}\n",
    "bin_2_tax_df = pd.read_csv(rootdir + \"metadata/bin2tax.tsv\", \"\\t\", names=[\"bin\", \"tax\"])\n",
    "for key, row in bin_2_tax_df.iterrows():\n",
    "    bin2tax_dict[row[\"bin\"]] = row[\"tax\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "makedir(rootdir + \"Scripts\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the SGA Database"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dereplication of the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#alex to fill out?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting protiens in each genome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alex too fill out?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Genome Annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KEGG, UniRef100, UniProt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gene taxonomic predictions USEARCH with UniRef100"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tree Construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CRISPR Cas Systems in SGA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CRISPR Cas Finder (CCF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cat all genomes\n",
    "print(\"cat {0}All_genomes/* > {0}All_genomes.fna\".format(rootdir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cat all proteins\n",
    "print(\"cat {0}All_genomes_proteins/* > {0}ALL_genome_proteins.faa\".format(rootdir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "makedir(rootdir + \"CCF_output_all_genomes\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#terminal command to run CRISPRcasfinder\n",
    "CRISPRCasFinder.pl -log -cpuM 16 -cpuP 16 -cas -rcfowce -gscf -faa /groups/banfield/projects/multienv/cpr/2020/tm7_sr1_gracili/Env_CPR_Alex/db_v3/All_database_proteins.faa -i rootdir/All_genomes.fna -out rootdir/CCF_output_all_genomes/"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "manually curated scaffolds with CCF 3 and 4 arrays to ensure they originated from SGA bacteria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in results\n",
    "ccf_output_df = pd.read_csv(rootdir + \"/CCF_output_all_genomes/TSV/Crisprs_REPORT.tsv\", sep=\"\\t\")\n",
    "#scaf 2 bin\n",
    "ccf_output_df[\"Bin\"] = ccf_output_df.Sequence.map(scaf2bin_dic)\n",
    "#bin 2 tax\n",
    "ccf_output_df[\"Lineage\"] = ccf_output_df.Bin.map(bin2tax_dict)\n",
    "#subset columns\n",
    "ccf_output_df = ccf_output_df[[\"Sequence\",\"Bin\",\"Lineage\", \"CRISPR_Start\", \"CRISPR_End\", \"Spacers_Nb\", \"Mean_size_Spacers\", \"Evidence_Level\"]].rename(columns={\"Sequence\":\"Scaffold\"})\n",
    "\n",
    "#adding in which scaffolds passed QC\n",
    "CCF_scaffold_QC_final_list_df = pd.read_csv(rootdir + \"/metadata/CCF_scaffold_QC_final_list.csv\")\n",
    "CCF_scaffold_QC_final_list_df = CCF_scaffold_QC_final_list_df.dropna()\n",
    "CCF_scaffold_QC_final_list_df = CCF_scaffold_QC_final_list_df[CCF_scaffold_QC_final_list_df[\"include\"]]\n",
    "\n",
    "QC_dict = {}\n",
    "for key, row in CCF_scaffold_QC_final_list_df.iterrows():\n",
    "    QC_dict[row[\"ccf_scaffold_name\"]] = row[\"include\"]\n",
    "\n",
    "ccf_output_df[\"Passed_manual_curation\"] = ccf_output_df.Scaffold.map(QC_dict)\n",
    "ccf_output_df[\"Passed_manual_curation\"] = ccf_output_df[\"Passed_manual_curation\"].fillna(False)\n",
    "\n",
    "ccf_output_df = ccf_output_df.sort_values(by=[\"Passed_manual_curation\", \"Lineage\", \"Evidence_Level\"], ascending=False)\n",
    "\n",
    "ccf_output_df.to_csv(rootdir + \"CCF_output_manual_curation.csv\", index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Searching for Cas genes"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#terminal command to run the hmm search with all tigrfams on the CPR genomes\n",
    "hmmsearch --cpu 16 -o rootdir/AlltigrfamHMMprofiles_to_cpr_db.txt --cut_nc ~/TIGRFAMs_15.0_HMM.LIB.hmm /groups/banfield/projects/multienv/cpr/2020/tm7_sr1_gracili/Env_CPR_Alex/db_v3/ALL_database_proteins.faa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hmm parse function\n",
    "def parse_hmm(result_table):\n",
    "    temp = {}\n",
    "    count = 0\n",
    "    # parse each result file using searchio\n",
    "    for result in SearchIO.parse(result_table, \"hmmer3-text\"):\n",
    "        for item in result.hits:\n",
    "            temp[count] = {\"gene\": item.id, \"score\": item.bitscore, \"eval\": item.evalue, \"query\": result.id, \"des\": result.description, \"accession\": result.accession}\n",
    "            count += 1\n",
    "    return(pd.DataFrame.from_dict(temp, orient=\"index\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#parse the tigrfam hmm results\n",
    "tigrfam_hmm_df = parse_hmm(rootdir + \"AlltigrfamHMMprofiles_to_cpr_db.txt\")\n",
    "\n",
    "#filtering tigrfam results based on evalue and dropping duplicates\n",
    "tigrfam_hmm_df_duplicates_dropped = tigrfam_hmm_df.sort_values(by=[\"eval\"]).drop_duplicates(subset=[\"gene\"])\n",
    "\n",
    "#only cas protein list\n",
    "tigrfam_hmm_df_duplicates_dropped_cas_only = tigrfam_hmm_df_duplicates_dropped[tigrfam_hmm_df_duplicates_dropped[\"des\"].str.contains(\"CRISPR\")]\n",
    "\n",
    "#simplify description\n",
    "tigrfam_hmm_df_duplicates_dropped_cas_only[\"des_simp\"] = tigrfam_hmm_df_duplicates_dropped[\"des\"].apply(lambda x: x.split(\":\")[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#manually constructed dictionary to categorize the called cas genes\n",
    "des_simp2_cas_category_dict = {\"cas2\":\"cas2\",\"cas_Csn1\":\"cas9\",\"cas1_NMENI\":\"cas1\",\"cas_Cpf1\":\"cpf1\",\"cas1_PREFRAN\":\"cas1\",\"cas4_PREFRAN\":\"cas4\",\"cas_Csn2\":\"csn2\",\"cas1\":\"cas1\",\"cas_cas6\":\"cas6\",\"cas7_TM1809\":\"cas7\",\"cas_TM1810_Csm2\":\"csm2\",\"cas_TM1811_Csm1\":\"cas10\",\"cas_TM1807_csm5\":\"cas7\",\"cas5_csm4\":\"cas5\",\"cas4\":\"cas4\",\"cas1_HMARI\":\"cas1\",\"TIGR03986\":\"TIGR03986\",\"cas_csf4\":\"csf4\",\"cas3_core\":\"cas3\",\"cas_Csd1\":\"cas8c\",\"cas_CXXC_CXXC\":\"cst1\",\"cas3_HD\":\"cas3\",\"cas_RAMP_Cmr4\":\"cas7\",\"cas_TM1791_cmr6\":\"cas7\",\"cas_cmr3\":\"cas5\",\"cas_Cas5d\":\"cas5\",\"cas_TM1794_Cmr2\":\"cas10\",\"cas_CT1132\":\"ct1132\",\"cas5_csf3\":\"cas5\",\"cas_Csh2\":\"cas7\",\"TIGR03984\":\"TIGR03984\",\"cas_TM1812\":\"TM1812\",\"cas_csx3\":\"csx3\",\"cas_Csy4\":\"cas6\",\"cas_Csy2\":\"csy2\",\"casB_cse2\":\"casB_cse2\",\"cas1_DVULG\":\"cas1\",\"cas3_yersinia\":\"cas3\",\"cas8u_csf1\":\"csf1\",\"cas_csm6\":\"csm6\",\"cas3_GSU0051\":\"cas3\",\"cas_Csy3\":\"csy3\",\"cas_csx17\":\"csx17\",\"cas_Csy1\":\"csy1\",\"cas_MJ0381\":\"MJ0381\",\"casA_cse1\":\"casA_cse1\",\"cas7_csf2\":\"csf2\",\"cas1_YPEST\":\"cas1\",\"cas_Csd2\":\"cas7\",\"cas_Cas5h\":\"cas5\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#subset table\n",
    "sub_tigrfam_hmm_df_duplicates_dropped_cas_only = tigrfam_hmm_df_duplicates_dropped_cas_only[[\"gene\",\"des_simp\"]]\n",
    "#grab scaffold name\n",
    "sub_tigrfam_hmm_df_duplicates_dropped_cas_only[\"scaffold\"] = sub_tigrfam_hmm_df_duplicates_dropped_cas_only[\"gene\"].apply(lambda x: x.rsplit(\"_\", 1)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding in bin and standarizing the Cas gene calls\n",
    "sub_tigrfam_hmm_df_duplicates_dropped_cas_only = sub_tigrfam_hmm_df_duplicates_dropped_cas_only.reset_index(drop=True)\n",
    "sub_tigrfam_hmm_df_duplicates_dropped_cas_only[\"bin\"] = sub_tigrfam_hmm_df_duplicates_dropped_cas_only[\"scaffold\"].map(scaf2bin_dic)\n",
    "\n",
    "sub_tigrfam_hmm_df_duplicates_dropped_cas_only[\"cas_type\"] = \"\"\n",
    "for inda in sub_tigrfam_hmm_df_duplicates_dropped_cas_only.index:\n",
    "    sub_tigrfam_hmm_df_duplicates_dropped_cas_only[\"cas_type\"][inda] = des_simp2_cas_category_dict[sub_tigrfam_hmm_df_duplicates_dropped_cas_only[\"des_simp\"][inda]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#subsetting to bins from our CCF QC scaffolds \n",
    "CCF_output_df = pd.read_csv(rootdir + \"/metadata/CCF_scaffold_QC_final_list.csv\")\n",
    "CCF_QC_bins = CCF_output_df[CCF_output_df.include == True][\"bin\"].unique()\n",
    "\n",
    "sub_tigrfam_hmm_df_duplicates_dropped_cas_only = sub_tigrfam_hmm_df_duplicates_dropped_cas_only[sub_tigrfam_hmm_df_duplicates_dropped_cas_only[\"bin\"].isin(CCF_QC_bins)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#manually curated all scaffolds containing Cas genes to ensure they were from SGA bacteria\n",
    "#read in these results\n",
    "manual_curation_parsed_df = pd.read_csv(rootdir + \"metadata/complete_cas_systems_manual_curation_parsed.csv\")\n",
    "manually_curated_scaffs = manual_curation_parsed_df[manual_curation_parsed_df.include == True][\"scaffold\"].unique()\n",
    "\n",
    "#subsetting to manually curated scaffolds\n",
    "sub_tigrfam_hmm_df_duplicates_dropped_cas_only = sub_tigrfam_hmm_df_duplicates_dropped_cas_only[sub_tigrfam_hmm_df_duplicates_dropped_cas_only.scaffold.isin(manually_curated_scaffs)]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Complete CRISPR-Cas system profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting cas_type counts\n",
    "sub_tigrfam_hmm_df_duplicates_dropped_cas_only_pivot = sub_tigrfam_hmm_df_duplicates_dropped_cas_only.groupby([\"bin\", \"cas_type\"], as_index=False).aggregate({\"gene\":\"count\"})\n",
    "sub_tigrfam_hmm_df_duplicates_dropped_cas_only_pivot.columns = [\"bin\", \"cas_type\", \"count\"]\n",
    "sub_tigrfam_hmm_df_duplicates_dropped_cas_only_pivot = sub_tigrfam_hmm_df_duplicates_dropped_cas_only_pivot.pivot(\"bin\", \"cas_type\", \"count\").fillna(0).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculating which systems and how many are in each genome\n",
    "bin2systems_number = {}\n",
    "bin2systems = {}\n",
    "sub_tigrfam_hmm_df_duplicates_dropped_cas_only_pivot_calc = sub_tigrfam_hmm_df_duplicates_dropped_cas_only_pivot.set_index(\"bin\")\n",
    "for key, row in sub_tigrfam_hmm_df_duplicates_dropped_cas_only_pivot_calc.iterrows():\n",
    "    bin_sys_list = []\n",
    "    #type IIA\n",
    "    while row[\"cas9\"] >0 and row[\"cas1\"] > 0 and row[\"cas2\"] > 0 and row[\"csn2\"] > 0:\n",
    "        bin_sys_list.append(\"Type II-A\")\n",
    "        row[\"cas9\"] = row[\"cas9\"] - 1\n",
    "        row[\"cas1\"] = row[\"cas1\"] - 1\n",
    "        row[\"cas2\"] = row[\"cas2\"] - 1\n",
    "        row[\"csn2\"] = row[\"csn2\"] - 1\n",
    "        continue\n",
    "    #type II-C1\n",
    "    while row[\"cas9\"] >0 and row[\"cas1\"] > 0 and row[\"cas2\"] > 0 and row[\"csn2\"] == 0:\n",
    "        bin_sys_list.append(\"Type II-C1\")\n",
    "        row[\"cas9\"] = row[\"cas9\"] - 1\n",
    "        row[\"cas1\"] = row[\"cas1\"] - 1\n",
    "        row[\"cas2\"] = row[\"cas2\"] - 1\n",
    "        continue\n",
    "    #type V-A\n",
    "    while row[\"cpf1\"] >0 and row[\"cas1\"] > 0 and row[\"cas2\"] > 0 and row[\"cas4\"] > 0:\n",
    "        bin_sys_list.append(\"Type V-A\")\n",
    "        row[\"cpf1\"] = row[\"cpf1\"] - 1\n",
    "        row[\"cas1\"] = row[\"cas1\"] - 1\n",
    "        row[\"cas2\"] = row[\"cas2\"] - 1\n",
    "        row[\"cas4\"] = row[\"cas4\"] - 1\n",
    "        continue\n",
    "    #type III-A\n",
    "    while row[\"cas10\"] >0 and row[\"cas7\"] > 0 and row[\"cas5\"] > 0 and row[\"csm2\"] > 0:\n",
    "        bin_sys_list.append(\"Type III-A\")\n",
    "        row[\"cas10\"] = row[\"cas10\"] - 1\n",
    "        row[\"cas7\"] = row[\"cas7\"] - 1\n",
    "        row[\"cas5\"] = row[\"cas5\"] - 1\n",
    "        row[\"csm2\"] = row[\"csm2\"] - 1\n",
    "        continue\n",
    "    #type III-B\n",
    "    while row[\"cas10\"] >0 and row[\"cas7\"] > 0 and row[\"cas5\"] > 0 and row[\"csm2\"] == 0:\n",
    "        bin_sys_list.append(\"Type III-B\")\n",
    "        row[\"cas10\"] = row[\"cas10\"] - 1\n",
    "        row[\"cas7\"] = row[\"cas7\"] - 1\n",
    "        row[\"cas5\"] = row[\"cas5\"] - 1\n",
    "        continue\n",
    "    bin2systems[key] = bin_sys_list\n",
    "    bin2systems_number[key] = len(bin_sys_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make systems dataframe\n",
    "complete_cas_systems_df = sub_tigrfam_hmm_df_duplicates_dropped_cas_only_pivot[[\"bin\"]].reset_index(drop=True)\n",
    "complete_cas_systems_df[\"Complete_CRISPR_Cas_Systems\"] = complete_cas_systems_df.bin.map(bin2systems)\n",
    "complete_cas_systems_df[\"Number_of_Complete_CRISPR_Cas_Systems\"] = complete_cas_systems_df.bin.map(bin2systems_number)\n",
    "\n",
    "\n",
    "#which bins have complete systems?\n",
    "complete_cas_systems_df[\"complete_cas_systems_boolean\"] = \"\"\n",
    "for indA in complete_cas_systems_df.index:\n",
    "    if str(complete_cas_systems_df[\"Complete_CRISPR_Cas_Systems\"][indA]) == \"[]\":\n",
    "        complete_cas_systems_df[\"complete_cas_systems_boolean\"][indA] = False\n",
    "    else:\n",
    "        complete_cas_systems_df[\"complete_cas_systems_boolean\"][indA] = True\n",
    "\n",
    "\n",
    "#add tax\n",
    "complete_cas_systems_df[\"tax\"] = complete_cas_systems_df.bin.map(bin2tax_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding in genes\n",
    "bin2genes_dict = {}\n",
    "for bin in sub_tigrfam_hmm_df_duplicates_dropped_cas_only.bin.unique():\n",
    "    sub_df = sub_tigrfam_hmm_df_duplicates_dropped_cas_only[sub_tigrfam_hmm_df_duplicates_dropped_cas_only.bin == bin]\n",
    "    sub_df = sub_df.sort_values(by=\"gene\", ascending=True)\n",
    "    genes_dict = {}\n",
    "    for key, row in sub_df.iterrows():\n",
    "        genes_dict[row[\"gene\"]] = row[\"des_simp\"]\n",
    "    bin2genes_dict[bin] = genes_dict\n",
    "\n",
    "complete_cas_systems_df[\"cas_genes\"] = complete_cas_systems_df.bin.map(bin2genes_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add in the CCF info\n",
    "ccf_output_df = pd.read_csv(rootdir + \"CCF_output_manual_curation.csv\")\n",
    "#manually curated scaffolds\n",
    "ccf_output_df = ccf_output_df[ccf_output_df.Passed_manual_curation == True]\n",
    "\n",
    "#make nested CCF dict\n",
    "ccf_dict = {}\n",
    "for bin in ccf_output_df.Bin.unique():\n",
    "    ccf_dict[bin] = {}\n",
    "    sub_df = ccf_output_df[ccf_output_df.Bin == bin]\n",
    "    array_count = 0\n",
    "    for key, row in sub_df.iterrows():\n",
    "        array_count += 1\n",
    "        ccf_dict[bin][\"CRISPR_array_\" + str(array_count)] = {}\n",
    "        ccf_dict[bin][\"CRISPR_array_\" + str(array_count)][\"Scaffold\"] = row[\"Scaffold\"]\n",
    "        ccf_dict[bin][\"CRISPR_array_\" + str(array_count)][\"CRISPR_Start\"] = row[\"CRISPR_Start\"]\n",
    "        ccf_dict[bin][\"CRISPR_array_\" + str(array_count)][\"CRISPR_End\"] = row[\"CRISPR_End\"]\n",
    "        ccf_dict[bin][\"CRISPR_array_\" + str(array_count)][\"Evidence_Level\"] = row[\"Evidence_Level\"]\n",
    "        ccf_dict[bin][\"CRISPR_array_\" + str(array_count)][\"Spacers_Nb\"] = row[\"Spacers_Nb\"]\n",
    "        ccf_dict[bin][\"CRISPR_array_\" + str(array_count)][\"Mean_size_Spacers\"] = row[\"Mean_size_Spacers\"]\n",
    "\n",
    "complete_cas_systems_df[\"CRISPR_Arrays\"] = complete_cas_systems_df.bin.map(ccf_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding in if the genomes are redundant or not\n",
    "drep_clusters = pd.read_csv(rootdir + \"metadata/drep_df.csv\")\n",
    "drep_clusters = drep_clusters.drop_duplicates(subset=[\"secondary_cluster\"])\n",
    "drep_genomes = drep_clusters.genome.str.replace(\".fna\", \"\")\n",
    "\n",
    "complete_cas_systems_df[\"Nonredundant\"] = \"\"\n",
    "for indA in complete_cas_systems_df.index:\n",
    "    if complete_cas_systems_df[\"bin\"][indA] in list(drep_genomes):\n",
    "        complete_cas_systems_df[\"Nonredundant\"][indA] = True\n",
    "    else:\n",
    "        complete_cas_systems_df[\"Nonredundant\"][indA] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the dataframe\n",
    "complete_cas_systems_df.to_csv(rootdir + \"Complete_Crispr_cas_systems_with_subtypes.csv\", index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clinker visualization of the CRISPR-Cas Systems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a scaffold2seq dict\n",
    "scaffold2seq = {}\n",
    "for file in glob.glob(rootdir + \"All_genomes/*fna\"):\n",
    "    for record in SeqIO.parse(open(file), \"fasta\"):\n",
    "        scaffold2seq[record.description.split(\" \")[0]] = str(record._seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tigrfam dict\n",
    "gene2tigr = {}\n",
    "for key, row in tigrfam_hmm_df_duplicates_dropped.iterrows():\n",
    "    gene2tigr[row[\"gene\"]] = row[\"des\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cat all proteins in the database\n",
    "print(\"cat {0}/All_genome_proteins/* > {0}All_genome_proteins.faa\".format(rootdir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#parsing the faa files\n",
    "genes_dict = defaultdict(list)\n",
    "for record in SeqIO.parse(rootdir + \"ALL_genome_proteins.faa\", \"fasta\"):\n",
    "    genes_dict[\"gene\"].append(record.id)\n",
    "    genes_dict[\"gene_number\"].append(int(record.id.rsplit(\"_\", 1)[1]))\n",
    "    genes_dict[\"scaffold\"].append(record.id.rsplit(\"_\", 1)[0])\n",
    "    genes_dict[\"bin\"].append(scaf2bin_dic[record.id.rsplit(\"_\", 1)[0]])\n",
    "    genes_dict[\"start\"].append(record.description.split(\" # \")[1])\n",
    "    genes_dict[\"stop\"].append(record.description.split(\" # \")[2])\n",
    "    genes_dict[\"direction\"].append(record.description.split(\" # \")[3])\n",
    "    genes_dict[\"seq\"].append(str(record._seq))\n",
    "\n",
    "genes_df = pd.DataFrame(genes_dict)\n",
    "\n",
    "#grab tigrfam annotations and cas descriptions\n",
    "genes_df[\"des\"] = genes_df[\"gene\"].map(gene2tigr)\n",
    "genes_df[\"des_simp\"] = genes_df[\"des\"].apply(lambda x: str(x).split(\":\")[0])\n",
    "genes_df[\"cas\"] = genes_df[\"des_simp\"].map(des_simp2_cas_category_dict)\n",
    "\n",
    "#seeing if bin is redundant\n",
    "genes_df[\"Nonredundant\"] = genes_df[\"bin\"].apply(lambda x: True if x in set(drep_genomes) else False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#looking for complete systems in the manually curated scaffolds, sliding window of 5 genes, grabbing all genes within the cas genes too \n",
    "systems = {}\n",
    "for scaffold in manually_curated_scaffs:\n",
    "    scaf_df = genes_df[genes_df.scaffold == scaffold]\n",
    "\n",
    "    #subset to only cas genes\n",
    "    cas_df = scaf_df[~scaf_df.cas.isna()].reset_index(drop=True)\n",
    "    system_count = 1\n",
    "    systems[scaffold] = {}\n",
    "    cas_gene_list = []\n",
    "    for indA in cas_df.index:\n",
    "        cas_gene_list.append(int(cas_df[\"gene_number\"][indA]))\n",
    "\n",
    "        #check if you are at the end of the cas_df\n",
    "        if indA == (len(cas_df) -1):\n",
    "            systems[scaffold][system_count] = list(range(min(cas_gene_list), max(cas_gene_list) +1))\n",
    "            continue\n",
    "\n",
    "        #checking if the next cas gene number is within 5 of the current cas gene, if not add 1 to system count, reset_system_gene_list\n",
    "        if int(cas_df[\"gene_number\"][indA + 1]) >= int(cas_df[\"gene_number\"][indA]) + 5:\n",
    "            systems[scaffold][system_count] = list(range(min(cas_gene_list), max(cas_gene_list) +1))\n",
    "            system_count += 1\n",
    "            cas_gene_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#map system_number back to genes_df\n",
    "gene_to_system = {}\n",
    "for scaffold in systems.keys():\n",
    "    for system_number in systems[scaffold].keys():\n",
    "        for gene_number in systems[scaffold][system_number]:\n",
    "            gene_to_system[scaffold + \"_\" + str(gene_number)] = scaffold + \"_system_\" + str(system_number)\n",
    "\n",
    "genes_df[\"crispr_cas_system\"] = genes_df.gene.map(gene_to_system)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#profiling the systems\n",
    "scafs = []\n",
    "for scaf in manually_curated_scaffs:\n",
    "    sub_df = genes_df[genes_df.scaffold == scaf]\n",
    "    #type II-A\n",
    "    if all(x in set(sub_df[\"cas\"]) for x in [\"cas9\", \"cas1\", \"cas2\", \"csn2\"]):\n",
    "        scafs.append(scaf)\n",
    "        continue\n",
    "\n",
    "    #type II-C1:\n",
    "    elif all(x in set(sub_df[\"cas\"]) for x in [\"cas9\", \"cas1\", \"cas2\"]):\n",
    "        scafs.append(scaf)\n",
    "        continue\n",
    "\n",
    "    #type V-A\n",
    "    elif all(x in set(sub_df[\"cas\"]) for x in [\"cpf1\", \"cas1\", \"cas2\", \"cas4\"]):\n",
    "        scafs.append(scaf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make folders\n",
    "makedir(rootdir + \"clinker_crispr_cas/\")\n",
    "makedir(rootdir + \"clinker_crispr_cas/type_two_A\")\n",
    "makedir(rootdir + \"clinker_crispr_cas/type_two_C1\")\n",
    "makedir(rootdir + \"clinker_crispr_cas/type_five_A\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make genebank files\n",
    "def make_genebank_record(dataframe, scaffold, crispr_cas_system):\n",
    "    record = SeqRecord(Seq(scaffold2seq[scaffold]), id=crispr_cas_system, name=crispr_cas_system, description=crispr_cas_system, annotations={\"molecule_type\": \"DNA\"})\n",
    "    for key, row in dataframe.iterrows():\n",
    "        gene_dict = OrderedDict()\n",
    "        gene_dict['product'] = row[\"des_simp\"]\n",
    "        gene_dict['codon_start'] = 1\n",
    "        gene_dict['gene'] = row[\"gene\"]\n",
    "        gene_dict['translation'] = row[\"seq\"]\n",
    "        gene = SeqFeature(FeatureLocation(start=int(row[\"start\"]), end=int(row[\"stop\"])), type='CDS', strand=int(row[\"direction\"]), qualifiers=gene_dict)\n",
    "        record.features.append(gene)\n",
    "    return record\n",
    "\n",
    "gene_bank_scafs = []\n",
    "for crispr_cas_system in genes_df.crispr_cas_system.unique():\n",
    "    sub_df = genes_df[genes_df.crispr_cas_system == crispr_cas_system][genes_df.Nonredundant == True]\n",
    "    scaffold = str(crispr_cas_system).split(\"_system_\")[0]\n",
    "    #type II-A systems:\n",
    "    if all(x in set(sub_df[\"cas\"]) for x in [\"cas9\", \"cas1\", \"cas2\", \"csn2\"]):\n",
    "        record = make_genebank_record(sub_df, scaffold, crispr_cas_system)\n",
    "        with open(rootdir + \"clinker_crispr_cas/type_two_A/{0}.gb\".format(crispr_cas_system), \"w\") as file:\n",
    "            SeqIO.write(record, file, 'genbank')\n",
    "        gene_bank_scafs.append(scaffold)\n",
    "        continue\n",
    "\n",
    "    #type II-C1:\n",
    "    elif all(x in set(sub_df[\"cas\"]) for x in [\"cas9\", \"cas1\", \"cas2\"]):\n",
    "        record = make_genebank_record(sub_df, scaffold, crispr_cas_system)\n",
    "        with open(rootdir + \"clinker_crispr_cas/type_two_C1/{0}.gb\".format(crispr_cas_system), \"w\") as file:\n",
    "            SeqIO.write(record, file, 'genbank')\n",
    "        gene_bank_scafs.append(scaffold)\n",
    "        continue\n",
    "\n",
    "    #type V-A\n",
    "    elif all(x in set(sub_df[\"cas\"]) for x in [\"cpf1\", \"cas1\", \"cas2\", \"cas4\"]):\n",
    "        record = make_genebank_record(sub_df, scaffold, crispr_cas_system)\n",
    "        with open(rootdir + \"clinker_crispr_cas/type_five_A/{0}.gb\".format(crispr_cas_system), \"w\") as file:\n",
    "            SeqIO.write(record, file, 'genbank')\n",
    "        gene_bank_scafs.append(scaffold)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#clinker commands\n",
    "clinker rootdir/clinker_crispr_cas/type_two_A/*.gb -p rootdir/clinker_crispr_cas/Type_two_A.html -j 4 --force\n",
    "clinker rootdir/clinker_crispr_cas/type_two_C1/*.gb -p rootdir/clinker_crispr_cas/type_two_C1.html -j 4 --force\n",
    "clinker rootdir/clinker_crispr_cas/type_five_A/*.gb -p /rootdir/clinker_crispr_cas/type_five_A.html -j 4 --force"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BLAST our curated cas genes to NCBI nr database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "makedir(rootdir + \"blast_cas_genes_to_NCBI\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make a fasta of the curated cas genes\n",
    "\n",
    "with open(rootdir + \"blast_cas_genes_to_NCBI/cas_genes.faa\", \"w\") as file:\n",
    "    for record in SeqIO.parse(rootdir + \"ALL_genome_proteins.faa\", \"fasta\"):\n",
    "        if record.id in list(sub_tigrfam_hmm_df_duplicates_dropped_cas_only.gene):\n",
    "            file.write(\">{0}\\n{1}\\n\".format(record.id, str(record._seq)))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#blast them \n",
    "blastp -num_threads 12 -evalue 1e-3 -sorthits 3 -outfmt 6 -query rootdir/blast_cas_genes_to_NCBI/cas_genes.faa -out rootdir/blast_cas_genes_to_NCBI/cas_genes.blast -db path_to_ncbi_nr_database/nr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read the results\n",
    "blast_output_df = skbio.io.read(rootdir + 'blast_cas_genes_to_NCBI/cas_genes.blast', format=\"blast+6\", into=pd.DataFrame, default_columns=True)\n",
    "#sort by pident, drop duplicates\n",
    "blast_output_df = blast_output_df.sort_values(by=[\"qseqid\", \"pident\"], ascending = [True, False]).drop_duplicates(subset=\"qseqid\")\n",
    "\n",
    "#at least 75% coverage\n",
    "blast_output_df[\"coverage\"] = blast_output_df[\"length\"]/(abs(blast_output_df[\"send\"] - blast_output_df[\"sstart\"]))\n",
    "blast_output_df = blast_output_df[blast_output_df.coverage >= 0.75]\n",
    "\n",
    "#add in cas type\n",
    "gene2cas_dict = {}\n",
    "for key, row in sub_tigrfam_hmm_df_duplicates_dropped_cas_only.iterrows():\n",
    "    gene2cas_dict[row[\"gene\"]] = row[\"cas_type\"]\n",
    "blast_output_df[\"cas_type\"] = blast_output_df.qseqid.map(gene2cas_dict)\n",
    "#add in scaffold and bin and taxonomy\n",
    "blast_output_df[\"scaffold\"] = blast_output_df.qseqid.apply(lambda x: x.rsplit(\"_\", 1)[0])\n",
    "blast_output_df[\"bin\"] = blast_output_df.scaffold.map(scaf2bin_dic)\n",
    "blast_output_df[\"tax\"] = blast_output_df.bin.map(bin2tax_dict)\n",
    "\n",
    "\n",
    "#dropping redundant genomes\n",
    "blast_output_df = blast_output_df.reset_index(drop=True)\n",
    "blast_output_df[\"Nonredundant\"] = \"\"\n",
    "for indA in blast_output_df.index:\n",
    "    if blast_output_df[\"bin\"][indA] in list(drep_genomes):\n",
    "        blast_output_df[\"Nonredundant\"][indA] = True\n",
    "    else:\n",
    "        blast_output_df[\"Nonredundant\"][indA] = False\n",
    "\n",
    "blast_output_df = blast_output_df[blast_output_df.Nonredundant == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot cas type to pident\n",
    "\n",
    "palette = {\"Gracilibacteria\":\"tab:green\",\n",
    "           \"Saccharibacteria\":\"tab:blue\", \n",
    "           \"Absconditabacteria\":\"tab:purple\"}\n",
    "\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "plt.figure(figsize=(12,5))\n",
    "sns.stripplot(x=\"cas_type\", y=\"pident\",hue=\"tax\", data=blast_output_df, jitter=0.3, linewidth=1, palette=palette, size =7, order=[\"cas1\", \"cas2\",\"cas9\",\"csn2\", \"cpf1\", \"cas4\", \"cas6\", \"cas10\", \"cas7\", \"cas5\", \"csm2\"])\n",
    "#sns.boxplot(x=\"cas_type\", y=\"pident\", data=blast_output_df, order=[\"cas1\", \"cas2\",\"cas9\",\"csn2\", \"cpf1\", \"cas4\", \"cas6\", \"cas10\", \"cas7\", \"cas5\", \"csm2\"])\n",
    "sns.despine()\n",
    "plt.xlabel('')\n",
    "plt.ylabel('Percent Identity (%)')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting spacers + Spacer array expansion steps"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CCF Spacers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "makedir(rootdir + \"CCF_output_all_genomes/spacer_fastas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract spacers from CCF evidence level 3 and 4 \n",
    "with open(rootdir + \"/CCF_output_all_genomes/result.json\", 'r') as f:\n",
    "    abs12_json = json.load(f)\n",
    "for abs12 in abs12_json['Sequences']:\n",
    "    for abs12_a in abs12['Crisprs']:\n",
    "        if abs12_a[\"Evidence_Level\"] == 4 or abs12_a[\"Evidence_Level\"] == 3:\n",
    "            for abs12_b in abs12_a['Regions']:\n",
    "                if \"Spacer\" in abs12_b[\"Type\"]:\n",
    "                    fasta = open(rootdir + 'CCF_output_all_genomes/spacer_fastas/' + abs12['Version'] + \"_\" + str(abs12_b[\"Start\"]) + '_CCF_spacer.fna', \"w\")\n",
    "                    header = (\">\" + abs12['Version'] + \"_\" + str(abs12_b[\"Start\"]))\n",
    "                    sequence = (abs12_b['Sequence'])\n",
    "                    fasta.write(header + \"\\n\" + sequence + \"\\n\")\n",
    "                    fasta.close()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#cat all the spacers together\n",
    "cat rootdir/CCF_output_all_genomes/spacer_fastas/*.fna > rootdir/CCF_output_all_genomes/all_ccf_spacers_3_4.fna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting ccf spacers from qc scaffolds \n",
    "#extracting spacers via pullseq\n",
    "script = open(rootdir + '/Scripts/extracting_ccf_spacers_from_qc_scaffolds.sh', \"w\")\n",
    "for x in CCF_scaffold_QC_final_list_df[\"ccf_scaffold_name\"]:\n",
    "        pullseq = \"pullseq -i {0}/CCF_output_all_genomes/all_ccf_spacers_3_4.fna -g \".format(rootdir)\n",
    "        pullseq2 = \" >> {0}/CCF_output_all_genomes/all_ccf_spacers_3_4_qc_scaffolds_only.fna\".format(rootdir)\n",
    "        script.write(pullseq + x + pullseq2 + \"\\n\")\n",
    "script.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "run the above script"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spacer array expansion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "makedir(rootdir + \"spacer_expansion\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in metadata info\n",
    "reassemble_info_df = pd.read_csv(rootdir + \"metadata/reassemble_genomes_from_reads_info.csv\")\n",
    "#remove unecessary columns\n",
    "reassemble_info_df = reassemble_info_df[[\"bin\", \"run_id\", \"read_path\", \"assembly_path\"]]\n",
    "#fillna\n",
    "reassemble_info_df = reassemble_info_df.fillna(\"None\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "makedir(rootdir + \"spacer_expansion/raw_reads/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Downloading reads from some publically avalible genomes\n",
    "script = open(rootdir + 'Scripts/download_reads_parallel_fastq_dump_split_files.sh', \"w\")\n",
    "for indA in reassemble_info_df.index:\n",
    "    bin_name = reassemble_info_df[\"bin\"][indA]\n",
    "    run_id = reassemble_info_df[\"run_id\"][indA]\n",
    "    if \"SRR\" in reassemble_info_df[\"run_id\"][indA]:\n",
    "        if reassemble_info_df[\"read_path\"][indA] != \"None\":\n",
    "            parallel_fastq_dump = \"{0}Scripts/parallel-fastq-dump --split-files -s <run_id> -t 16 -O {0}/spacer_expansion/raw_reads/ --gzip\".format(rootdir)\n",
    "            parallel_fastq_dump = parallel_fastq_dump.replace(\"<run_id>\", run_id)\n",
    "            script.write(\"#\" + bin_name + \"_\" + run_id + \"\\n\" + parallel_fastq_dump + \"\\n\")\n",
    "script.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "run download_reads_parallel_fastq_dump_split_files.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#quality control reads #split-files\n",
    "script = open(rootdir + 'Scripts/quality_control_reads_split_files.sh', \"w\")\n",
    "for indA in reassemble_info_df.index:\n",
    "    bin_name = reassemble_info_df[\"bin\"][indA]\n",
    "    run_id = reassemble_info_df[\"run_id\"][indA]\n",
    "\n",
    "    if \"SRR\" in reassemble_info_df[\"run_id\"][indA]:\n",
    "        if reassemble_info_df[\"read_path\"][indA] != \"None\":\n",
    "            quality_control_1 = \"{0}Scripts/process_reads_bbmap.rb -p 16 -z --create-fa {0}spacer_expansion/raw_reads/<run_id>_1_quality_controlled.fasta --basename {0}/spacer_expansion/raw_reads/<run_id>_1\".format(rootdir)\n",
    "            quality_control_1 = quality_control_1.replace(\"<run_id>\", run_id)\n",
    "            quality_control_2 = \"{0}Scripts/process_reads_bbmap.rb -p 16 -z --create-fa /{0}spacer_expansion/raw_reads/<run_id>_2_quality_controlled.fasta --basename {0}spacer_expansion/raw_reads/<run_id>_2\".format(rootdir)\n",
    "            quality_control_2 = quality_control_2.replace(\"<run_id>\", run_id)\n",
    "            script.write(\"#\" + bin_name + \"_\" + run_id + \"\\n\" + quality_control_1 + \"\\n\" + quality_control_2 + \"\\n\")\n",
    "script.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "run quality_control_reads_split_files.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "makedir(rootdir + \"spacer_expansion/assembly/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#assembly of fastq dump genomes #split_reads\n",
    "script = open(rootdir + 'Scripts/assembly_of_fastq_dump_genomes_split_reads.sh', \"w\")\n",
    "for indA in reassemble_info_df.index:\n",
    "    bin_name = reassemble_info_df[\"bin\"][indA]\n",
    "    run_id = reassemble_info_df[\"run_id\"][indA]\n",
    "\n",
    "    if \"SRR\" in reassemble_info_df[\"run_id\"][indA]:\n",
    "        if reassemble_info_df[\"read_path\"][indA] != \"None\":\n",
    "            mkdir = \"mkdir {0}/spacer_expansion/assembly/<run_id>/\".format(rootdir)\n",
    "            mkdir = mkdir.replace(\"<run_id>\", run_id)\n",
    "            megahit = \"sbatch --wrap 'megahit -t 48 -1 {0}spacer_expansion/raw_reads/<run_id>_trim_clean.PE.1.fastq.gz -2 {0}spacer_expansion/raw_reads/<run_id>_trim_clean.PE.2.fastq.gz -o {0}/spacer_expansion/assembly/<run_id>/megahit/ --out-prefix <run_id>'\".format(rootdir)\n",
    "            megahit = megahit.replace(\"<run_id>\", run_id)\n",
    "            script.write(\"#\" + bin_name + \"_\" + run_id + \"\\n\" + mkdir + \"\\n\" + megahit + \"\\n\")\n",
    "script.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "run assembly_of_fastq_dump_genomes_split_reads.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mapping with bowtie 2 fastq #split reads\n",
    "script = open(rootdir + 'Scripts/mapping_of_fastq_dump_genomes_split_reads.sh', \"w\")\n",
    "for indA in reassemble_info_df.index:\n",
    "    bin_name = reassemble_info_df[\"bin\"][indA]\n",
    "    run_id = reassemble_info_df[\"run_id\"][indA]\n",
    "    if \"SRR\" in reassemble_info_df[\"run_id\"][indA]:\n",
    "        if reassemble_info_df[\"read_path\"][indA] != \"None\":\n",
    "            mkdir_2 = \"mkdir {0}/spacer_expansion/assembly/<run_id>/bt2/\".format(rootdir)\n",
    "            mkdir_2 = mkdir_2.replace(\"<run_id>\", run_id)\n",
    "            bt2_build = \"bowtie2-build {0}/spacer_expansion/assembly/<run_id>/megahit/<run_id>.contigs.fa {0}/spacer_expansion/assembly/<run_id>/bt2/<run_id>.contigs.fa\".format(rootdir)\n",
    "            bt2_build = bt2_build.replace(\"<bin_name>\", bin_name).replace(\"<run_id>\", run_id)\n",
    "            bt2 = \"sbatch --wrap '/shared/software/bin/bowtie2 -p 48 -x {0}/spacer_expansion/assembly/<run_id>/bt2/<run_id>.contigs.fa -1 {0}spacer_expansion/raw_reads/<run_id>_trim_clean.PE.1.fastq.gz -2 {0}spacer_expansion/raw_reads/<run_id>_trim_clean.PE.2.fastq.gz 2> {0}/spacer_expansion/assembly/<run_id>/bt2/<run_id>_log_file.log | shrinksam | samtools view -S -b > {0}/spacer_expansion/assembly/<run_id>/bt2/<run_id>.bam'\".format(rootdir)\n",
    "            bt2 = bt2.replace(\"<bin_name>\", bin_name).replace(\"<run_id>\", run_id)\n",
    "            script.write(\"#\" + bin_name + \"_\" + run_id + \"\\n\" + mkdir_2 + \"\\n\" + bt2_build + \"\\n\" + bt2 + \"\\n\")\n",
    "script.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "run mapping_of_fastq_dump_genomes_split_reads.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "makedir(rootdir + \"spacer_expansion/expansion_output/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#running lin Xing's script V6 on fastq_dump_genomes\n",
    "script = open(rootdir + \"Scripts/lin_xing_v6_script_of_fastq_dump_genomes.sh\", \"w\")\n",
    "for indA in reassemble_info_df.index:\n",
    "    bin_name = reassemble_info_df[\"bin\"][indA]\n",
    "    run_id = reassemble_info_df[\"run_id\"][indA]\n",
    "    if \"SRR\" in reassemble_info_df[\"run_id\"][indA]:\n",
    "        if reassemble_info_df[\"read_path\"][indA] != \"None\":\n",
    "            assembly_path = \"{0}/spacer_expansion/assembly/<run_id>/megahit/<run_id>.contigs.fa\".replace(\"<run_id>\", run_id).format(rootdir)\n",
    "            bam_path = \"{0}/spacer_expansion/assembly/<run_id>/bt2/<run_id>.bam\".replace(\"<run_id>\", run_id).format(rootdir)\n",
    "            lin_xing_script = \"{0}Scripts/CRISPR.v6.py -f <assembly_path> -m <bam_path> -c 16 -n 16 -o {0}/spacer_expansion/expansion_output/<bin_name>/\".format(rootdir)\n",
    "            lin_xing_script = lin_xing_script.replace(\"<assembly_path>\", assembly_path).replace(\"<bam_path>\", bam_path).replace(\"<bin_name>\", bin_name)\n",
    "            script.write(\"#\" + bin_name + \"_\" + run_id + \"\\n\" + lin_xing_script + \"\\n\")\n",
    "script.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "run lin_xing_v6_script_of_fastq_dump_genomes.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Blast assembled scaffolds to publically avalible scaffolds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "makedir(rootdir + \"spacer_expansion/blast_output/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#blast script\n",
    "file = open(rootdir + \"Scripts/blast_assembled_scaffolds_to_public_scaffolds.sh\", \"w\")\n",
    "for indA in reassemble_info_df.index:\n",
    "\n",
    "    if \"SRR\" in reassemble_info_df[\"run_id\"][indA]:\n",
    "        if reassemble_info_df[\"read_path\"][indA] != \"None\":\n",
    "\n",
    "            bin_name = reassemble_info_df[\"bin\"][indA]\n",
    "            run_id = reassemble_info_df[\"run_id\"][indA]\n",
    "            public_genome_path = \"{0}/All_genomes/<bin_name>.fna\".replace(\"<bin_name>\", bin_name).format(rootdir)\n",
    "            db_path = \"{0}/spacer_expansion/assembly/<run_id>/megahit/<run_id>.contigs.fa\".replace(\"<run_id>\", run_id).format(rootdir)\n",
    "            blast_db = \"makeblastdb -in <db_path> -dbtype nucl\"\n",
    "            blast_db = blast_db.replace(\"<db_path>\", db_path)\n",
    "            blast_command = \"blastn -task 'blastn-short' -query <public_genome_path> -db <db_path> -outfmt '6 qseqid sseqid pident length mismatch gapopen qstart qend sstart send evalue bitscore qlen slen' -out /groups/banfield/projects/multienv/cpr/2020/tm7_sr1_gracili/Env_CPR_Alex/db_v4/Blast_assembled_scaffolds_public_output/blast_output/<bin_name>_<run_id>_ALL_results.csv -evalue 0.003 -word_size 7 -gapopen 10 -gapextend 2 -penalty -1 -max_target_seqs 1000 -num_threads 16\".replace(\"<bin_name>\", bin_name).replace(\"<run_id>\", run_id)\n",
    "            blast_command = blast_command.replace(\"<public_genome_path>\", public_genome_path).replace(\"<db_path>\", db_path)\n",
    "            file.write(\"#\" + bin_name + \"\\n\" + blast_db + \"\\n\" + blast_command + \"\\n\")\n",
    "file.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "run blast_assembled_scaffolds_to_public_scaffolds.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in blast results and concatonate\n",
    "blast_results_dfs = []\n",
    "for file in glob.glob(rootdir + \"spacer_expansion/blast_output/*\"):\n",
    "    blast_df = skbio.io.read(file, format=\"blast+6\", into=pd.DataFrame, default_columns=False,  columns=['qseqid', 'sseqid', 'pident', 'length', 'mismatch', 'gapopen', 'qstart', 'qend', 'sstart', 'send', 'evalue', 'bitscore', 'qlen', 'slen'])\n",
    "    blast_results_dfs.append(blast_df)\n",
    "\n",
    "all_blast_results_df = pd.concat(blast_results_dfs)\n",
    "\n",
    "#caluculate coverage\n",
    "all_blast_results_df[\"Coverage\"] = all_blast_results_df['length']/all_blast_results_df['slen']\n",
    "all_blast_results_df = all_blast_results_df[all_blast_results_df[\"Coverage\"] > 0.95]\n",
    "\n",
    "# choose best scaffold by pident\n",
    "all_blast_results_df = all_blast_results_df.sort_values(by=[\"pident\"], ascending=False)\n",
    "all_blast_results_df = all_blast_results_df.drop_duplicates(subset=[\"qseqid\"])\n",
    "\n",
    "#rename columns\n",
    "all_blast_results_df = all_blast_results_df.rename(columns={\"qseqid\":\"ccf_scaffold_name\", \"sseqid\":\"assembled_scaffold_name\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "public_qc_scaffolds_final_list = pd.read_csv(rootdir + \"metadata/CCF_scaffold_QC_final_list.csv\")\n",
    "public_qc_scaffolds_final_list = public_qc_scaffolds_final_list.dropna()\n",
    "public_qc_scaffolds_final_list = public_qc_scaffolds_final_list[public_qc_scaffolds_final_list[\"include\"] == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge with list of manually QC scaffolds\n",
    "merged_public_assembled_scaffolds = public_qc_scaffolds_final_list.merge(all_blast_results_df, on=\"ccf_scaffold_name\", how=\"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save these results\n",
    "merged_public_assembled_scaffolds.to_csv(rootdir + \"metadata/merged_public_assembled_scaffolds.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cating additional spacers from spacer expansion\n",
    "print(\"cat {0}spacer_expansion/expansion_output/*/spacers.fasta >> {0}spacer_expansion/all_additional_spacers.fa\".format(rootdir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extracting spacers via pullseq for QC scaffolds\n",
    "for x in merged_public_assembled_scaffolds[\"assembled_scaffold_name\"]:\n",
    "        pullseq = \"pullseq -i {0}spacer_expansion/all_additional_spacers.fa -g {1} >> {0}spacer_expansion/qc_additional_spacers.fa\".format(rootdir, x)\n",
    "        os.system(pullseq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#combining lin xing + ccf spacers\n",
    "print(\"cat {0}spacer_expansion/qc_additional_spacers.fa {0}/CCF_output_all_genomes/all_ccf_spacers_3_4_qc_scaffolds_only.fna > {0}All_qc_spacers.fna\".format(rootdir))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#drep spacers\n",
    "usearch -cluster_fast rootdir/All_qc_spacers.fna -sort length -id 1 -centroids {0}All_qc_spacers_derepped.fna"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
